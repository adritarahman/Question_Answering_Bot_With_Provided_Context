{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"0da5ee95bdbf47a995e314d9e6d00676":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c4f957bc6474918b46f7221a14e590c","placeholder":"​","style":"IPY_MODEL_f81d72793f8b422ebf0808e622744a50","value":"special_tokens_map.json: 100%"}},"0e6066b73c634aa483e26f5ab398c6d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8fd0121ad6243f7832aa09b6cf3f2cb","placeholder":"​","style":"IPY_MODEL_3abe4a1af09d4a408bf8eaf93e846bfd","value":" 456k/? [00:00&lt;00:00, 18.3MB/s]"}},"1280b6a459074e87b38833891b6d6301":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"157a2a8a1f96422b847b6d1c54443b2f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"158354a72812477291c99832347a9360":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e53a33d9f2e943ac94e4562adb92b503","IPY_MODEL_fdca3b9d16d54d5badf3d634eeaeebac","IPY_MODEL_96f3511d52f94fd4ba0f39b36a790fdb"],"layout":"IPY_MODEL_6d6ca33ca89046bbabde32ef2620eb39"}},"1849ef05774a4114a36b19cf7f92617b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87bad6418e44420c9e7b1809dc2b8bc2","placeholder":"​","style":"IPY_MODEL_19260272fb124b92a39076e1530c33ae","value":" 496M/496M [00:06&lt;00:00, 60.0MB/s]"}},"19260272fb124b92a39076e1530c33ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a30f337e89d4143a47a01b8cc1f10c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1b5aed66aa3a4009b3cf98b69654470b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"1ee0f65478f94732aa97fd948da8fc65":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fa697016ebc4e7bbd8c556fa0e3e4a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2180c61468ac451aa1e19d596d5ccbf1":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_1fa697016ebc4e7bbd8c556fa0e3e4a1","msg_id":"","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Testing <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 2643/2643 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:04:46 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">9.27it/s</span>  \n</pre>\n","text/plain":"Testing \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 2643/2643 \u001b[2m0:04:46 • 0:00:00\u001b[0m \u001b[2;4m9.27it/s\u001b[0m  \n"},"metadata":{},"output_type":"display_data"}]}},"2c4f957bc6474918b46f7221a14e590c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d314eb158a94622ae952cac13321145":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b142e84ecf5a435ab2a2147bb32961d6","placeholder":"​","style":"IPY_MODEL_b47db4fdb3594617ac843e7b02976b70","value":" 772/772 [00:00&lt;00:00, 79.6kB/s]"}},"2fbd61da58f64f86800439edd2127082":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e52f908b76d448a3854b11fab03130cb","IPY_MODEL_88125dbb4be24fd6ac82db0682a0268b","IPY_MODEL_c44e50da9e254243a2148eb52840458e"],"layout":"IPY_MODEL_f285da7a3a4d44cfa29bc50eac9eb049"}},"3694ca75a66447fda3a34162b14da024":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"390f8b9dac054371b5b21b0d757ce8ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3abe4a1af09d4a408bf8eaf93e846bfd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bb5a0d21a59456082577aa802b413ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bf13d693fe240998a91ebfe651a3813":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_477a6fc21d4143baa9db6eeff8436f08","max":571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4ff197d408124f7ab0f78b0afed0411b","value":571}},"3e76ba7f09274815994ccbd79b527a9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c8c12515be5841a88e22178dd4215a4f","IPY_MODEL_7fdd9318b1744d6b957e745922947eb3","IPY_MODEL_0e6066b73c634aa483e26f5ab398c6d5"],"layout":"IPY_MODEL_dec4da40180648a98927aabc7db89f94"}},"3ea21ac47841470196f46b0f40225b7f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4031564301b546c39c8f54738015593f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"436054e805d74db5890fdf0a89056a2c":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_4a072bb5c4244a5a916f070bb5b6c8f7","msg_id":"","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 0/-2 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 500/500 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:03:25 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">2.42it/s</span> <span style=\"font-style: italic\">v_num: 2.000 train_loss: 0.647</span>\n</pre>\n","text/plain":"Epoch 0/-2 \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 500/500 \u001b[2m0:03:25 • 0:00:00\u001b[0m \u001b[2;4m2.42it/s\u001b[0m \u001b[3mv_num: 2.000 train_loss: 0.647\u001b[0m\n"},"metadata":{},"output_type":"display_data"}]}},"477a6fc21d4143baa9db6eeff8436f08":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"496c43818e5d489492eb4e69cc4cb98c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a072bb5c4244a5a916f070bb5b6c8f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ff197d408124f7ab0f78b0afed0411b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"568e4482896e473eb65e1d1a4f321b88":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b8e00755a0f458f8b80f21a2ca6e99d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97dcb66af4454b8fbf52cf6e85634f5f","max":772,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3ea21ac47841470196f46b0f40225b7f","value":772}},"6402a8faa9374ac0b48977e12fa02364":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d6ca33ca89046bbabde32ef2620eb39":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71ee618156b9410ebde5c7fd0f860c1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_390f8b9dac054371b5b21b0d757ce8ee","placeholder":"​","style":"IPY_MODEL_c22f1ef132874430b1ba48f8ef788d89","value":"config.json: 100%"}},"74103e950adf45b4a02fb992fa58c37c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"74fcb5e34e7c4321adabed80ec0d30dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b86171a70f84e9d97aa023a5b45332e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6402a8faa9374ac0b48977e12fa02364","placeholder":"​","style":"IPY_MODEL_e959d4463f3f4e7db6601ccea8c007f9","value":"model.safetensors: 100%"}},"7e1ecca5c1d2453c9a410b403cd6603d":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_568e4482896e473eb65e1d1a4f321b88","msg_id":"","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Testing <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 2643/2643 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:04:52 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">9.03it/s</span>  \n</pre>\n","text/plain":"Testing \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 2643/2643 \u001b[2m0:04:52 • 0:00:00\u001b[0m \u001b[2;4m9.03it/s\u001b[0m  \n"},"metadata":{},"output_type":"display_data"}]}},"7fdd9318b1744d6b957e745922947eb3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_927349033dee4ebb970c615ac1404676","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad50b154fd7c48d6a1c5fbf89052e96e","value":1}},"808b7503acfc4831becf87f2db7c6663":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"831955145ad84ceeba6b3134ffde757c":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_496c43818e5d489492eb4e69cc4cb98c","msg_id":"","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 0/-2 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 500/500 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:03:17 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">2.46it/s</span> <span style=\"font-style: italic\">v_num: 0.000 train_loss: 1.810</span>\n</pre>\n","text/plain":"Epoch 0/-2 \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 500/500 \u001b[2m0:03:17 • 0:00:00\u001b[0m \u001b[2;4m2.46it/s\u001b[0m \u001b[3mv_num: 0.000 train_loss: 1.810\u001b[0m\n"},"metadata":{},"output_type":"display_data"}]}},"87b73af5a77644c2b65d9b65ec009a9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87bad6418e44420c9e7b1809dc2b8bc2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88125dbb4be24fd6ac82db0682a0268b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_808b7503acfc4831becf87f2db7c6663","max":79,"min":0,"orientation":"horizontal","style":"IPY_MODEL_895a1e98f78d4fa4828f61f5a779c75a","value":79}},"895a1e98f78d4fa4828f61f5a779c75a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8bae4e518b4742c4b16e23671a5e5117":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0da5ee95bdbf47a995e314d9e6d00676","IPY_MODEL_5b8e00755a0f458f8b80f21a2ca6e99d","IPY_MODEL_2d314eb158a94622ae952cac13321145"],"layout":"IPY_MODEL_fdf7ac4bcf0649bbb8458aad5cf9d5f9"}},"8c19e6a27d134d0c8644df89ff7232f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"927349033dee4ebb970c615ac1404676":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"96726720019849d091b17a96a16331a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fcd86c3c4534b798bd8efab36553470","max":496254442,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1a30f337e89d4143a47a01b8cc1f10c9","value":496254442}},"96f3511d52f94fd4ba0f39b36a790fdb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5bfbbd786414d18a03176d769c3df16","placeholder":"​","style":"IPY_MODEL_87b73af5a77644c2b65d9b65ec009a9b","value":" 899k/? [00:00&lt;00:00, 37.5MB/s]"}},"97dcb66af4454b8fbf52cf6e85634f5f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fcd86c3c4534b798bd8efab36553470":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad50b154fd7c48d6a1c5fbf89052e96e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b142e84ecf5a435ab2a2147bb32961d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b47db4fdb3594617ac843e7b02976b70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7208f8460c345cf98369e0790f67b71":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8fd0121ad6243f7832aa09b6cf3f2cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c22f1ef132874430b1ba48f8ef788d89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c44e50da9e254243a2148eb52840458e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3694ca75a66447fda3a34162b14da024","placeholder":"​","style":"IPY_MODEL_b7208f8460c345cf98369e0790f67b71","value":" 79.0/79.0 [00:00&lt;00:00, 7.51kB/s]"}},"c5bfbbd786414d18a03176d769c3df16":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8c12515be5841a88e22178dd4215a4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_157a2a8a1f96422b847b6d1c54443b2f","placeholder":"​","style":"IPY_MODEL_74fcb5e34e7c4321adabed80ec0d30dd","value":"merges.txt: "}},"c9947af5423e4d1eae5628cff297026b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b86171a70f84e9d97aa023a5b45332e","IPY_MODEL_96726720019849d091b17a96a16331a9","IPY_MODEL_1849ef05774a4114a36b19cf7f92617b"],"layout":"IPY_MODEL_cf98ac1bee1b4a50a8fea412f6e0b457"}},"cf98ac1bee1b4a50a8fea412f6e0b457":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dec4da40180648a98927aabc7db89f94":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e52f908b76d448a3854b11fab03130cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c19e6a27d134d0c8644df89ff7232f0","placeholder":"​","style":"IPY_MODEL_1280b6a459074e87b38833891b6d6301","value":"tokenizer_config.json: 100%"}},"e53a33d9f2e943ac94e4562adb92b503":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ee0f65478f94732aa97fd948da8fc65","placeholder":"​","style":"IPY_MODEL_4031564301b546c39c8f54738015593f","value":"vocab.json: "}},"e82124fa312f4f5998a9957d89bd38ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_71ee618156b9410ebde5c7fd0f860c1b","IPY_MODEL_3bf13d693fe240998a91ebfe651a3813","IPY_MODEL_fb0d80daba6545b6b7206781b18bf979"],"layout":"IPY_MODEL_3bb5a0d21a59456082577aa802b413ba"}},"e959d4463f3f4e7db6601ccea8c007f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec26aa03cbd144eca3cd8014c87c2372":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f285da7a3a4d44cfa29bc50eac9eb049":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f81d72793f8b422ebf0808e622744a50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb0d80daba6545b6b7206781b18bf979":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff1d02eedc5f4350897c82a03593cfdc","placeholder":"​","style":"IPY_MODEL_ec26aa03cbd144eca3cd8014c87c2372","value":" 571/571 [00:00&lt;00:00, 34.1kB/s]"}},"fdca3b9d16d54d5badf3d634eeaeebac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b5aed66aa3a4009b3cf98b69654470b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_74103e950adf45b4a02fb992fa58c37c","value":1}},"fdf7ac4bcf0649bbb8458aad5cf9d5f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff1d02eedc5f4350897c82a03593cfdc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install pytorch_lightning","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ylrvpUM3izVr","outputId":"3f12229f-e248-440f-f0e9-9aa6770e84cd","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T16:23:14.487512Z","iopub.execute_input":"2026-01-30T16:23:14.487720Z","iopub.status.idle":"2026-01-30T16:23:20.337910Z","shell.execute_reply.started":"2026-01-30T16:23:14.487697Z","shell.execute_reply":"2026-01-30T16:23:20.336897Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.12/dist-packages (2.6.0)\nRequirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (2.8.0+cu126)\nRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (4.67.1)\nRequirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (6.0.3)\nRequirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2025.10.0)\nRequirement already satisfied: torchmetrics>0.7.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (1.8.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (26.0rc2)\nRequirement already satisfied: typing-extensions>4.5.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (4.15.0)\nRequirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (0.15.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.13.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.20.3)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.4.0)\nRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics>0.7.0->pytorch_lightning) (2.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.22.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->pytorch_lightning) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (3.0.3)\nRequirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.11)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from pytorch_lightning.utilities.types import OptimizerLRScheduler","metadata":{"id":"dYN7wMh7klFG","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T16:23:38.310697Z","iopub.execute_input":"2026-01-30T16:23:38.311154Z","iopub.status.idle":"2026-01-30T16:23:58.899925Z","shell.execute_reply.started":"2026-01-30T16:23:38.311120Z","shell.execute_reply":"2026-01-30T16:23:58.899283Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pytorch_lightning as pl\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertForQuestionAnswering, BertTokenizer\nfrom torch.optim import AdamW\nimport pandas as pd","metadata":{"id":"M5RvxiM4jB96","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T16:24:02.961940Z","iopub.execute_input":"2026-01-30T16:24:02.962718Z","iopub.status.idle":"2026-01-30T16:24:25.679146Z","shell.execute_reply.started":"2026-01-30T16:24:02.962684Z","shell.execute_reply":"2026-01-30T16:24:25.678532Z"}},"outputs":[{"name":"stderr","text":"2026-01-30 16:24:06.522722: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769790246.920778      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769790247.041619      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769790248.100432      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769790248.100473      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769790248.100477      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769790248.100491      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"torch.manual_seed(42)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aj8fcRlUjMiE","outputId":"b80a3ad8-0a95-4335-f323-891a2829e448","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T16:24:35.015393Z","iopub.execute_input":"2026-01-30T16:24:35.015990Z","iopub.status.idle":"2026-01-30T16:24:35.021959Z","shell.execute_reply.started":"2026-01-30T16:24:35.015960Z","shell.execute_reply":"2026-01-30T16:24:35.021334Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import gdown\nimport os\n\n\nfolder_id = '1Hkkt5pzvpHXk_dHCNl62HOpnvzfuy1RG'\nurl = f'https://drive.google.com/drive/folders/{folder_id}'\n\n\noutput_dir = '/kaggle/working/my_dataset'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\ngdown.download_folder(url, output=output_dir, quiet=False, remaining_ok=True)\n\n\nprint(\"Files in dataset folder:\", os.listdir(output_dir))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T16:36:12.780094Z","iopub.execute_input":"2026-01-30T16:36:12.780504Z","iopub.status.idle":"2026-01-30T16:36:29.052285Z","shell.execute_reply.started":"2026-01-30T16:36:12.780475Z","shell.execute_reply":"2026-01-30T16:36:29.051682Z"}},"outputs":[{"name":"stderr","text":"Retrieving folder contents\n","output_type":"stream"},{"name":"stdout","text":"Processing file 1aru0XD4-QEXtObYk92hCU5eYO4AmrSeo qna_test.csv\nProcessing file 1rqRraaaDduNElM3i9W9IS6iiv81QXWZc qna_train.csv\nProcessing file 13dYYmfC4mZQEL5rdLAg4xRxJt9OXJKLq QnA_with_llm.ipynb\n","output_type":"stream"},{"name":"stderr","text":"Retrieving folder contents completed\nBuilding directory structure\nBuilding directory structure completed\nDownloading...\nFrom: https://drive.google.com/uc?id=1aru0XD4-QEXtObYk92hCU5eYO4AmrSeo\nTo: /kaggle/working/my_dataset/qna_test.csv\n100%|██████████| 10.2M/10.2M [00:00<00:00, 37.7MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1rqRraaaDduNElM3i9W9IS6iiv81QXWZc\nTo: /kaggle/working/my_dataset/qna_train.csv\n100%|██████████| 77.3M/77.3M [00:01<00:00, 64.0MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=13dYYmfC4mZQEL5rdLAg4xRxJt9OXJKLq\nTo: /kaggle/working/my_dataset/QnA_with_llm.ipynb\n100%|██████████| 118k/118k [00:00<00:00, 72.3MB/s]","output_type":"stream"},{"name":"stdout","text":"Files in dataset folder: ['qna_test.csv', 'qna_train.csv', 'QnA_with_llm.ipynb']\n","output_type":"stream"},{"name":"stderr","text":"\nDownload completed\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"class QnADataset(Dataset):\n    def __init__(self, df, tokenizer):\n        self.df = df\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        context = self.df.iloc[idx]['context']\n        question = self.df.iloc[idx]['question']\n        answers = eval(self.df.iloc[idx]['answers'])['text'][0]\n        answer_start = eval(self.df.iloc[idx]['answers'])['answer_start'][0]\n\n        try:\n            tokens = self.tokenizer.encode_plus(\n                context,\n                question,\n                add_special_tokens=True,\n                max_length=512,\n                truncation=True,\n                padding='max_length',\n                return_tensors='pt',\n                return_offsets_mapping=True\n                )\n        except Exception as e:\n            tokens = {\n                'input_ids': torch.zeros(512, dtype=torch.long),\n                'attention_mask': torch.zeros(512, dtype=torch.long),\n                'offset_mapping': torch.zeros((512, 2), dtype=torch.long),\n            }\n\n        input_ids = tokens['input_ids'].squeeze()\n        attention_mask = tokens['attention_mask'].squeeze()\n        offset_mapping = tokens['offset_mapping'].squeeze()\n\n        start_position = 0\n        end_position = 0\n        answer_end = answer_start + len(answers)\n\n        for i, (start_char, end_char) in enumerate(offset_mapping):\n            if start_char <= answer_start < end_char:\n                start_position = i\n            if start_char < answer_end <= end_char:\n                end_position = i\n                break\n\n        return {\n            'input_ids': input_ids,\n            'attention_mask': attention_mask,\n            'start_positions': torch.tensor([start_position], dtype=torch.long),\n            'end_positions': torch.tensor([end_position], dtype=torch.long),\n        }\n","metadata":{"id":"TqjTfgH3jPVM","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T16:37:00.187549Z","iopub.execute_input":"2026-01-30T16:37:00.188124Z","iopub.status.idle":"2026-01-30T16:37:00.195952Z","shell.execute_reply.started":"2026-01-30T16:37:00.188089Z","shell.execute_reply":"2026-01-30T16:37:00.195230Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class QnADataModule(pl.LightningDataModule):\n    def __init__(self, train_data_path, test_data_path, tokenizer):\n        super().__init__()\n        self.train_data_path = train_data_path\n        self.test_data_path = test_data_path\n        self.tokenizer = tokenizer\n\n    def setup(self, stage=None):\n        train_df = pd.read_csv(self.train_data_path)\n        test_df = pd.read_csv(self.test_data_path)\n        self.train_ds = QnADataset(train_df, self.tokenizer)\n        self.test_ds = QnADataset(test_df, self.tokenizer)\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.train_ds,\n            batch_size=4,\n            shuffle=True,\n        )\n    def test_dataloader(self):\n        return DataLoader(\n            self.test_ds,\n            batch_size=4,\n            shuffle=False,\n        )","metadata":{"id":"rpOdpbNfjkjM","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T16:37:05.636794Z","iopub.execute_input":"2026-01-30T16:37:05.637127Z","iopub.status.idle":"2026-01-30T16:37:05.642593Z","shell.execute_reply.started":"2026-01-30T16:37:05.637099Z","shell.execute_reply":"2026-01-30T16:37:05.641858Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from transformers import AutoModelForQuestionAnswering\n\n\nclass QnAModel(pl.LightningModule):\n    def __init__(self, model_name='deepset/roberta-base-squad2'):\n        super().__init__()\n        self.model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n\n    def forward(self, input_ids, attention_mask, start_positions, end_positions):\n        outputs = self.model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            start_positions=start_positions,\n            end_positions=end_positions,\n        )\n        return outputs\n    def training_step(self, batch, batch_idx):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        start_positions = batch['start_positions'].to(device)\n        end_positions = batch['end_positions'].to(device)\n        outputs = self.forward(input_ids,attention_mask,start_positions,end_positions)\n\n        loss = outputs.loss\n        self.log('train_loss', loss, prog_bar=True)\n        return loss\n    def test_step(self, batch, batch_idx):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        start_positions = batch['start_positions'].to(device)\n        end_positions = batch['end_positions'].to(device)\n        outputs = self.forward(input_ids,attention_mask,start_positions,end_positions)\n\n        loss = outputs.loss\n        self.log('test_loss', loss, prog_bar=True)\n        return loss\n\n    def configure_optimizers(self):\n        return AdamW(params=self.parameters(), lr=5e-5, eps=1e-8)","metadata":{"id":"GQegaV6jjqk-","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T16:37:22.775841Z","iopub.execute_input":"2026-01-30T16:37:22.776152Z","iopub.status.idle":"2026-01-30T16:37:22.783407Z","shell.execute_reply.started":"2026-01-30T16:37:22.776122Z","shell.execute_reply":"2026-01-30T16:37:22.782572Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_name = 'deepset/roberta-base-squad2'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nmodel = QnAModel()\nds_module = QnADataModule(\n    train_data_path=\"/kaggle/working/my_dataset/qna_train.csv\",\n    test_data_path=\"/kaggle/working/my_dataset/qna_test.csv\",\n    tokenizer=tokenizer\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333,"referenced_widgets":["2fbd61da58f64f86800439edd2127082","e52f908b76d448a3854b11fab03130cb","88125dbb4be24fd6ac82db0682a0268b","c44e50da9e254243a2148eb52840458e","f285da7a3a4d44cfa29bc50eac9eb049","8c19e6a27d134d0c8644df89ff7232f0","1280b6a459074e87b38833891b6d6301","808b7503acfc4831becf87f2db7c6663","895a1e98f78d4fa4828f61f5a779c75a","3694ca75a66447fda3a34162b14da024","b7208f8460c345cf98369e0790f67b71","e82124fa312f4f5998a9957d89bd38ed","71ee618156b9410ebde5c7fd0f860c1b","3bf13d693fe240998a91ebfe651a3813","fb0d80daba6545b6b7206781b18bf979","3bb5a0d21a59456082577aa802b413ba","390f8b9dac054371b5b21b0d757ce8ee","c22f1ef132874430b1ba48f8ef788d89","477a6fc21d4143baa9db6eeff8436f08","4ff197d408124f7ab0f78b0afed0411b","ff1d02eedc5f4350897c82a03593cfdc","ec26aa03cbd144eca3cd8014c87c2372","158354a72812477291c99832347a9360","e53a33d9f2e943ac94e4562adb92b503","fdca3b9d16d54d5badf3d634eeaeebac","96f3511d52f94fd4ba0f39b36a790fdb","6d6ca33ca89046bbabde32ef2620eb39","1ee0f65478f94732aa97fd948da8fc65","4031564301b546c39c8f54738015593f","1b5aed66aa3a4009b3cf98b69654470b","74103e950adf45b4a02fb992fa58c37c","c5bfbbd786414d18a03176d769c3df16","87b73af5a77644c2b65d9b65ec009a9b","3e76ba7f09274815994ccbd79b527a9c","c8c12515be5841a88e22178dd4215a4f","7fdd9318b1744d6b957e745922947eb3","0e6066b73c634aa483e26f5ab398c6d5","dec4da40180648a98927aabc7db89f94","157a2a8a1f96422b847b6d1c54443b2f","74fcb5e34e7c4321adabed80ec0d30dd","927349033dee4ebb970c615ac1404676","ad50b154fd7c48d6a1c5fbf89052e96e","b8fd0121ad6243f7832aa09b6cf3f2cb","3abe4a1af09d4a408bf8eaf93e846bfd","8bae4e518b4742c4b16e23671a5e5117","0da5ee95bdbf47a995e314d9e6d00676","5b8e00755a0f458f8b80f21a2ca6e99d","2d314eb158a94622ae952cac13321145","fdf7ac4bcf0649bbb8458aad5cf9d5f9","2c4f957bc6474918b46f7221a14e590c","f81d72793f8b422ebf0808e622744a50","97dcb66af4454b8fbf52cf6e85634f5f","3ea21ac47841470196f46b0f40225b7f","b142e84ecf5a435ab2a2147bb32961d6","b47db4fdb3594617ac843e7b02976b70","c9947af5423e4d1eae5628cff297026b","7b86171a70f84e9d97aa023a5b45332e","96726720019849d091b17a96a16331a9","1849ef05774a4114a36b19cf7f92617b","cf98ac1bee1b4a50a8fea412f6e0b457","6402a8faa9374ac0b48977e12fa02364","e959d4463f3f4e7db6601ccea8c007f9","9fcd86c3c4534b798bd8efab36553470","1a30f337e89d4143a47a01b8cc1f10c9","87bad6418e44420c9e7b1809dc2b8bc2","19260272fb124b92a39076e1530c33ae"]},"id":"TodOvyLBj2yJ","outputId":"a32608fd-d028-4059-960e-238ef4a7d9fd","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T16:37:53.360675Z","iopub.execute_input":"2026-01-30T16:37:53.361228Z","iopub.status.idle":"2026-01-30T16:37:57.927438Z","shell.execute_reply.started":"2026-01-30T16:37:53.361148Z","shell.execute_reply":"2026-01-30T16:37:57.926585Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cc4f3c0b0304380b195454f22e65528"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b440ff3c8aa4e0b9df19f69279848ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d6e1b1d54c84fbe8b3f3fdf26888a33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85eec49a0c4f40df80a30d7c1fe0cea6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9baedac4d2ea47f2afdf647f231645f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82a4deae344b462190bfd45ed9fe7a7f"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"trainer = pl.Trainer(\n    max_steps=500\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xxG0tiw5j6tu","outputId":"762334da-0022-4843-ea06-9023946ba0a2","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T16:38:07.647087Z","iopub.execute_input":"2026-01-30T16:38:07.647849Z","iopub.status.idle":"2026-01-30T16:38:07.712714Z","shell.execute_reply.started":"2026-01-30T16:38:07.647812Z","shell.execute_reply":"2026-01-30T16:38:07.712001Z"}},"outputs":[{"name":"stderr","text":"Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# trainer.fit(model, ds_module)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321,"referenced_widgets":["831955145ad84ceeba6b3134ffde757c","496c43818e5d489492eb4e69cc4cb98c"]},"id":"Ey7nEJd8j9R1","outputId":"5f8b35d2-046a-41fd-e594-cf30c33688cf"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━┳━━━━━━━┓\n","┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                        </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n","┡━━━╇━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━╇━━━━━━━┩\n","│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model │ RobertaForQuestionAnswering │  124 M │ eval │     0 │\n","└───┴───────┴─────────────────────────────┴────────┴──────┴───────┘\n","</pre>\n"],"text/plain":["┏━━━┳━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━┳━━━━━━━┓\n","┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                       \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\n","┡━━━╇━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━╇━━━━━━━┩\n","│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ model │ RobertaForQuestionAnswering │  124 M │ eval │     0 │\n","└───┴───────┴─────────────────────────────┴────────┴──────┴───────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                                            \n","<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n","<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                                                \n","<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 496                                                                        \n","<span style=\"font-weight: bold\">Modules in train mode</span>: 0                                                                                           \n","<span style=\"font-weight: bold\">Modules in eval mode</span>: 227                                                                                          \n","<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n","</pre>\n"],"text/plain":["\u001b[1mTrainable params\u001b[0m: 124 M                                                                                            \n","\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n","\u001b[1mTotal params\u001b[0m: 124 M                                                                                                \n","\u001b[1mTotal estimated model params size (MB)\u001b[0m: 496                                                                        \n","\u001b[1mModules in train mode\u001b[0m: 0                                                                                           \n","\u001b[1mModules in eval mode\u001b[0m: 227                                                                                          \n","\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"831955145ad84ceeba6b3134ffde757c","version_major":2,"version_minor":0},"text/plain":["Output()"]},"metadata":{}},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py:534: Found 227 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=500` reached.\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"],"text/plain":[]},"metadata":{},"output_type":"display_data"}],"execution_count":null},{"cell_type":"code","source":"# trainer.test(model=model, datamodule=ds_module)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":148,"referenced_widgets":["2180c61468ac451aa1e19d596d5ccbf1","1fa697016ebc4e7bbd8c556fa0e3e4a1"]},"id":"NDICC9xHkAOb","outputId":"b94dc89e-5643-4afa-831a-5da2958c212a"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2180c61468ac451aa1e19d596d5ccbf1","version_major":2,"version_minor":0},"text/plain":["Output()"]},"metadata":{}},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.2798359394073486     </span>│\n","└───────────────────────────┴───────────────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.2798359394073486    \u001b[0m\u001b[35m \u001b[0m│\n","└───────────────────────────┴───────────────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"],"text/plain":[]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["[{'test_loss': 1.2798359394073486}]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"execution_count":null},{"cell_type":"code","source":"pip install mlflow","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AZMnoEcdpyZh","outputId":"6990c35b-24ab-476b-de96-d46d2d2c723a","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T16:38:21.385322Z","iopub.execute_input":"2026-01-30T16:38:21.385904Z","iopub.status.idle":"2026-01-30T16:38:36.529799Z","shell.execute_reply.started":"2026-01-30T16:38:21.385871Z","shell.execute_reply":"2026-01-30T16:38:36.528730Z"}},"outputs":[{"name":"stdout","text":"Collecting mlflow\n  Downloading mlflow-3.9.0-py3-none-any.whl.metadata (31 kB)\nCollecting mlflow-skinny==3.9.0 (from mlflow)\n  Downloading mlflow_skinny-3.9.0-py3-none-any.whl.metadata (32 kB)\nCollecting mlflow-tracing==3.9.0 (from mlflow)\n  Downloading mlflow_tracing-3.9.0-py3-none-any.whl.metadata (19 kB)\nCollecting Flask-CORS<7 (from mlflow)\n  Downloading flask_cors-6.0.2-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.1.2)\nRequirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.17.0)\nRequirement already satisfied: cryptography<47,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (46.0.3)\nRequirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (7.1.0)\nCollecting graphene<4 (from mlflow)\n  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\nCollecting gunicorn<24 (from mlflow)\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nCollecting huey<3,>=2.5.4 (from mlflow)\n  Downloading huey-2.6.0-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.10.0)\nRequirement already satisfied: numpy<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.2)\nRequirement already satisfied: pandas<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.2.2)\nRequirement already satisfied: pyarrow<23,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (22.0.0)\nRequirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.6.1)\nRequirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.15.3)\nCollecting skops<1 (from mlflow)\n  Downloading skops-0.13.0-py3-none-any.whl.metadata (5.6 kB)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.44)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (5.5.2)\nRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (8.3.1)\nRequirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (3.1.1)\nCollecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.9.0->mlflow)\n  Downloading databricks_sdk-0.82.0-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (0.123.10)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (3.1.45)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (8.7.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (1.37.0)\nRequirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (1.37.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (1.37.0)\nCollecting packaging<26 (from mlflow-skinny==3.9.0->mlflow)\n  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (5.29.5)\nRequirement already satisfied: pydantic<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (2.12.5)\nRequirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (1.1.1)\nRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (6.0.3)\nRequirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (2.32.5)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (0.5.3)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (4.15.0)\nRequirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (0.38.0)\nRequirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\nRequirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow) (2.6.3)\nRequirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (1.9.0)\nRequirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.6)\nRequirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.0.3)\nRequirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.3)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (4.60.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.4.9)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (11.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (3.2.5)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (1.5.3)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\nRequirement already satisfied: prettytable>=3.9 in /usr/local/lib/python3.12/dist-packages (from skops<1->mlflow) (3.16.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.4)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=2.0.0->cryptography<47,>=43.0.0->mlflow) (2.23)\nRequirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (2.47.0)\nRequirement already satisfied: starlette<0.51.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.9.0->mlflow) (0.50.0)\nRequirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.9.0->mlflow) (0.0.4)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.9.0->mlflow) (4.0.12)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.9.0->mlflow) (3.23.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.9.0->mlflow) (0.58b0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable>=3.9->skops<1->mlflow) (0.2.14)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow) (0.4.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (3.11)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (2026.1.4)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==3.9.0->mlflow) (0.16.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.9.0->mlflow) (5.0.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (4.9.1)\nRequirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.9.0->mlflow) (4.12.1)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (0.6.1)\nDownloading mlflow-3.9.0-py3-none-any.whl (9.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading mlflow_skinny-3.9.0-py3-none-any.whl (2.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading mlflow_tracing-3.9.0-py3-none-any.whl (1.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading flask_cors-6.0.2-py3-none-any.whl (13 kB)\nDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huey-2.6.0-py3-none-any.whl (76 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading skops-0.13.0-py3-none-any.whl (131 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.2/131.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading databricks_sdk-0.82.0-py3-none-any.whl (789 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m789.2/789.2 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nDownloading packaging-25.0-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: huey, packaging, graphql-core, gunicorn, graphql-relay, skops, graphene, Flask-CORS, databricks-sdk, mlflow-tracing, mlflow-skinny, mlflow\n  Attempting uninstall: packaging\n    Found existing installation: packaging 26.0rc2\n    Uninstalling packaging-26.0rc2:\n      Successfully uninstalled packaging-26.0rc2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.47.0 which is incompatible.\ngoogle-colab 1.0.0 requires jupyter-server==2.14.0, but you have jupyter-server 2.12.5 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\ncudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ngradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nfastai 2.8.4 requires fastcore<1.9,>=1.8.0, but you have fastcore 1.11.3 which is incompatible.\npylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Flask-CORS-6.0.2 databricks-sdk-0.82.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 gunicorn-23.0.0 huey-2.6.0 mlflow-3.9.0 mlflow-skinny-3.9.0 mlflow-tracing-3.9.0 packaging-25.0 skops-0.13.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import mlflow\nimport mlflow.transformers\nfrom mlflow.models.signature import infer_signature\nimport shutil","metadata":{"id":"9V0s1UHyp6H_","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T16:38:44.586483Z","iopub.execute_input":"2026-01-30T16:38:44.586813Z","iopub.status.idle":"2026-01-30T16:38:48.640519Z","shell.execute_reply.started":"2026-01-30T16:38:44.586777Z","shell.execute_reply":"2026-01-30T16:38:48.639616Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"\n\nimport os\n\n\nmlflow.set_tracking_uri(\"file:///kaggle/working/mlruns\")\n\nmlflow.set_experiment(experiment_name=\"QnA_with_LLM\")\n\nif not os.path.exists(\"/kaggle/working/mlruns\"):\n    os.makedirs(\"/kaggle/working/mlruns\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cqzyVNUMqCNI","outputId":"ad9d37a7-4ac1-4265-e996-2f9032bd4405","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T16:40:22.154296Z","iopub.execute_input":"2026-01-30T16:40:22.155158Z","iopub.status.idle":"2026-01-30T16:40:22.176763Z","shell.execute_reply.started":"2026-01-30T16:40:22.155122Z","shell.execute_reply":"2026-01-30T16:40:22.176053Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/mlflow/tracking/_tracking_service/utils.py:178: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n  return FileStore(store_uri, store_uri)\n2026/01/30 16:40:22 INFO mlflow.tracking.fluent: Experiment with name 'QnA_with_LLM' does not exist. Creating a new experiment.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"LEARNING_RATE = 5e-5\nBATCH_SIZE = 4\nMAX_STEPS = 500","metadata":{"id":"wXMUtmG_qFBF","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T16:40:41.796955Z","iopub.execute_input":"2026-01-30T16:40:41.797270Z","iopub.status.idle":"2026-01-30T16:40:41.801537Z","shell.execute_reply.started":"2026-01-30T16:40:41.797241Z","shell.execute_reply":"2026-01-30T16:40:41.800770Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import os\nARTIFACT_FOLDER_NAME = \"qa_model\"\nSOURCE_CODE_PATH = '/kaggle/working/my_dataset/QnA_with_llm.ipynb'\nSOURCE_CODE_ARTIFACT = 'trainer.ipynb'","metadata":{"id":"2e4MmYRCqI_4","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T16:40:59.006977Z","iopub.execute_input":"2026-01-30T16:40:59.007576Z","iopub.status.idle":"2026-01-30T16:40:59.010997Z","shell.execute_reply.started":"2026-01-30T16:40:59.007541Z","shell.execute_reply":"2026-01-30T16:40:59.010284Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# mlflow.end_run()\nwith mlflow.start_run() as run:\n\n\n    # Log hyperparameters\n    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n    mlflow.log_param(\"max_steps\", MAX_STEPS)\n\n\n    # Initialize model and datamodule\n    model = QnAModel(model_name='deepset/roberta-base-squad2')\n    ds_module = QnADataModule(\n        train_data_path=\"/kaggle/working/my_dataset/qna_train.csv\",\n        test_data_path=\"/kaggle/working/my_dataset/qna_test.csv\",\n        tokenizer=tokenizer\n    )\n    ds_module.setup()\n    trainer = pl.Trainer(\n        max_steps=MAX_STEPS,\n     )\n\n    trainer.fit(\n        model=model,\n        train_dataloaders=ds_module.train_dataloader(),\n\n    )\n\n    score = trainer.test(\n        model=model,\n        dataloaders=ds_module.test_dataloader()\n     )\n    test_loss = score[0][\"test_loss\"]\n    mlflow.log_metric(\"test_loss\", test_loss)\n\n    temp_save_dir = \"/kaggle/working/temp_model_files\"\n\n    # Clean up any old temp files from previous failed runs\n    if os.path.exists(temp_save_dir):\n        shutil.rmtree(temp_save_dir)\n    os.makedirs(temp_save_dir)\n\n    model.model.save_pretrained(temp_save_dir)\n    tokenizer.save_pretrained(temp_save_dir)\n\n    mlflow.log_artifacts(temp_save_dir, artifact_path=ARTIFACT_FOLDER_NAME)\n\n\n    if os.path.exists(SOURCE_CODE_PATH):\n        shutil.copyfile(SOURCE_CODE_PATH, SOURCE_CODE_ARTIFACT)\n        mlflow.log_artifact(SOURCE_CODE_ARTIFACT)\n        print(\"✅ Source code logged.\")\n    else:\n        print(f\"⚠️ Note: {SOURCE_CODE_PATH} not found. skipping notebook log.\")\n\n    # Capture IDs for verification\n    run_id = run.info.run_id\n    exp_id = run.info.experiment_id\n\nmlflow.end_run()\nimport time\ntime.sleep(10)\n\nfinal_path = f\"/kaggle/working/mlruns/{exp_id}/{run_id}/artifacts/{ARTIFACT_FOLDER_NAME}\"\n\nif os.path.exists(final_path):\n    files = os.listdir(final_path)\n    print(f\"✅ SUCCESS! Artifacts found at: {final_path}\")\n    print(f\"Files found: {files}\")\n    if \"model.safetensors\" in files or \"pytorch_model.bin\" in files:\n        print(\"💎 PROOF: Weights are physically on disk.\")\nelse:\n    print(f\"❌ ERROR: Artifacts are still not in {final_path}\")\n    print(\"Checking if mlruns exists at all:\")\n    \n\n\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":556,"referenced_widgets":["436054e805d74db5890fdf0a89056a2c","4a072bb5c4244a5a916f070bb5b6c8f7","7e1ecca5c1d2453c9a410b403cd6603d","568e4482896e473eb65e1d1a4f321b88"]},"id":"akaEXPX-qXwf","outputId":"d50d1d4e-44a5-4a20-c047-406648ae8c72","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T16:43:23.235174Z","iopub.execute_input":"2026-01-30T16:43:23.235771Z","iopub.status.idle":"2026-01-30T16:51:49.479862Z","shell.execute_reply.started":"2026-01-30T16:43:23.235738Z","shell.execute_reply":"2026-01-30T16:51:49.478882Z"}},"outputs":[{"name":"stderr","text":"Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"┏━━━┳━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━┳━━━━━━━┓\n┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                       \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\n┡━━━╇━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━╇━━━━━━━┩\n│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ model │ RobertaForQuestionAnswering │  124 M │ eval │     0 │\n└───┴───────┴─────────────────────────────┴────────┴──────┴───────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━┳━━━━━━━┓\n┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                        </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n┡━━━╇━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━╇━━━━━━━┩\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model │ RobertaForQuestionAnswering │  124 M │ eval │     0 │\n└───┴───────┴─────────────────────────────┴────────┴──────┴───────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mTrainable params\u001b[0m: 124 M                                                                                            \n\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n\u001b[1mTotal params\u001b[0m: 124 M                                                                                                \n\u001b[1mTotal estimated model params size (MB)\u001b[0m: 496                                                                        \n\u001b[1mModules in train mode\u001b[0m: 0                                                                                           \n\u001b[1mModules in eval mode\u001b[0m: 227                                                                                          \n\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                                            \n<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                                                \n<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 496                                                                        \n<span style=\"font-weight: bold\">Modules in train mode</span>: 0                                                                                           \n<span style=\"font-weight: bold\">Modules in eval mode</span>: 227                                                                                          \n<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b79a11570d65468a827a1627c9dc7d86"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py:534: Found 227 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n`Trainer.fit` stopped: `max_steps=500` reached.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"name":"stderr","text":"LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfd3fff8810c419098580e659d2a6dd0"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    4.489785671234131    \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     4.489785671234131     </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"name":"stdout","text":"✅ Source code logged.\n✅ SUCCESS! Artifacts found at: /kaggle/working/mlruns/706558397354895962/0f4ce9983d6a404081fbdadf04b46adb/artifacts/qa_model\nFiles found: ['vocab.json', 'tokenizer.json', 'config.json', 'merges.txt', 'model.safetensors', 'tokenizer_config.json', 'special_tokens_map.json']\n💎 PROOF: Weights are physically on disk. You are ready to zip!\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import shutil\nfrom IPython.display import FileLink\n\n\nartifact_src = '/kaggle/working/mlruns/706558397354895962/0f4ce9983d6a404081fbdadf04b46adb/artifacts/qa_model'\n\n\nshutil.make_archive('qa_weights', 'zip', artifact_src)\n\n\nFileLink(r'qa_weights.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:04:30.297095Z","iopub.execute_input":"2026-01-30T17:04:30.297753Z","iopub.status.idle":"2026-01-30T17:04:55.050843Z","shell.execute_reply.started":"2026-01-30T17:04:30.297718Z","shell.execute_reply":"2026-01-30T17:04:55.050049Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/qa_weights.zip","text/html":"<a href='qa_weights.zip' target='_blank'>qa_weights.zip</a><br>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"!pip install pyngrok --quiet\nfrom pyngrok import ngrok\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:16:29.241201Z","iopub.execute_input":"2026-01-30T17:16:29.242041Z","iopub.status.idle":"2026-01-30T17:16:32.710389Z","shell.execute_reply.started":"2026-01-30T17:16:29.242004Z","shell.execute_reply":"2026-01-30T17:16:32.709449Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nfrom pyngrok import ngrok\nimport os\n\n\n!fuser -k 5000/tcp\nngrok.kill()\n\n\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"ngrok\")\nngrok.set_auth_token(secret_value_0)\n\n\nget_ipython().system_raw(\"mlflow ui --port 5000 --host 0.0.0.0 --allowed-hosts '*' &\")\n\n# 4. Create the tunnel\ntry:\n    public_url = ngrok.connect(5000)\n    print(\"\\n\" + \"=\"*50)\n    print(f\"🚀 FIXED LINK: {public_url.public_url}\")\n    print(\"=\"*50)\nexcept Exception as e:\n    print(f\"❌ Connection failed: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:40:17.110185Z","iopub.execute_input":"2026-01-30T17:40:17.111149Z","iopub.status.idle":"2026-01-30T17:40:17.946558Z","shell.execute_reply.started":"2026-01-30T17:40:17.111106Z","shell.execute_reply":"2026-01-30T17:40:17.945703Z"}},"outputs":[{"name":"stdout","text":"5000/tcp:              563   565   566   567   568\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\n🚀 FIXED LINK: https://nonreductive-noncognizably-frida.ngrok-free.dev\n==================================================\nWARNING: Accepting ALL hosts. This may leave the server vulnerable to DNS rebinding attacks.\nBackend store URI not provided. Using ./mlruns\nRegistry store URI not provided. Using backend store URI.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/mlflow/server/handlers.py:310: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n  return FileStore(store_uri, artifact_uri)\n/usr/local/lib/python3.12/dist-packages/mlflow/server/handlers.py:339: FutureWarning: The filesystem model registry backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n  return FileStore(store_uri)\n[MLflow] Security middleware enabled. Allowed hosts: *.\n2026/01/30 17:40:20 WARNING mlflow.server: MLflow job execution requirements not met (MLflow job backend requires a database backend store URI but got ./mlruns). Server will start without job execution support. Errors will be surfaced at job invocation time.\nINFO:     Uvicorn running on http://0.0.0.0:5000 (Press CTRL+C to quit)\nINFO:     Started parent process [667]\nINFO:     Started server process [672]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Started server process [671]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Started server process [669]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Started server process [670]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\n","output_type":"stream"},{"name":"stdout","text":"INFO:     103.150.255.236:0 - \"GET / HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/main.9e6a97ae.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/css/main.280d6c90.css HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/TelemetryLogger.telemetry-worker.e586432cbf500042667b.worker.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/783.b107ace8.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /ajax-api/3.0/mlflow/assistant/config HTTP/1.1\" 403 Forbidden\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/3528.18b15e38.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/3617.f09cade8.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/css/547.26533251.chunk.css HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/4205.1aba6fbf.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /ajax-api/3.0/mlflow/ui-telemetry HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/547.e6974a2b.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /ajax-api/2.0/mlflow/experiments/search?max_results=5&order_by=last_update_time+DESC HTTP/1.1\" 200 OK\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/mlflow/server/handlers.py:310: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n  return FileStore(store_uri, artifact_uri)\n","output_type":"stream"},{"name":"stdout","text":"INFO:     103.150.255.236:0 - \"GET /static-files/manifest.json HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/favicon.ico HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/css/4783.26533251.chunk.css HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/4783.4aec66f2.chunk.js HTTP/1.1\" 200 OK\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/mlflow/server/handlers.py:310: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n  return FileStore(store_uri, artifact_uri)\n","output_type":"stream"},{"name":"stdout","text":"INFO:     103.150.255.236:0 - \"GET /ajax-api/2.0/mlflow/experiments/search?max_results=25&order_by=last_update_time+DESC HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/8799.5c4e7066.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/2365.07e09cf7.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/6016.68aefba1.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/6844.ac50e035.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/css/6844.fd7db8ca.chunk.css HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /server-info HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"POST /graphql HTTP/1.1\" 200 OK\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/mlflow/server/handlers.py:310: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n  return FileStore(store_uri, artifact_uri)\n","output_type":"stream"},{"name":"stdout","text":"INFO:     103.150.255.236:0 - \"GET /ajax-api/2.0/mlflow/traces?experiment_ids=706558397354895962&order_by=timestamp_ms%20DESC&max_results=1&filter= HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"POST /ajax-api/2.0/mlflow/runs/search HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/4499.994fae84.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/8813.ace4e4fc.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/683.3a1461a5.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/2763.b4138d32.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/7913.519d3aaf.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/4266.22041e7b.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/6360.0f91997c.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/5532.b1e5a8e4.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/css/9563.3a1ae3b9.chunk.css HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"POST /ajax-api/3.0/mlflow/ui-telemetry HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/6478.44078de0.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/2354.a425cb01.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/5641.e03eeeda.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/4139.195847b8.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/8664.7ec14180.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/9042.5a1e98a9.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/4395.8dc882e6.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/4802.bf5d0f64.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/1241.1d9f1d6c.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/1573.1309c53b.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/9563.941d9737.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"POST /ajax-api/3.0/mlflow/ui-telemetry HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"POST /ajax-api/2.0/mlflow/experiments/search-datasets HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/css/1575.05d081e5.chunk.css HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/5964.dd9e117c.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /static-files/static/js/1575.c083428a.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"GET /ajax-api/2.0/mlflow/gateway-proxy?gateway_path=api%2F2.0%2Fendpoints%2F HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"POST /ajax-api/2.0/mlflow/logged-models/search HTTP/1.1\" 200 OK\nINFO:     103.150.255.236:0 - \"POST /ajax-api/2.0/mlflow/runs/search HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /static-files/static/js/1876.078219d8.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /static-files/static/js/6831.c13e3357.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /static-files/static/js/3702.526c85d9.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /static-files/static/css/1172.b80374b9.chunk.css HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /static-files/static/js/6301.62669e82.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /static-files/static/js/1352.370969cc.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /static-files/static/js/1009.1c9b622f.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"POST /ajax-api/2.0/mlflow/runs/search HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /static-files/static/js/1172.2c68c87c.chunk.js HTTP/1.1\" 200 OK\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/mlflow/server/handlers.py:339: FutureWarning: The filesystem model registry backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n  return FileStore(store_uri)\n/usr/local/lib/python3.12/dist-packages/mlflow/server/handlers.py:339: FutureWarning: The filesystem model registry backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n  return FileStore(store_uri)\n","output_type":"stream"},{"name":"stdout","text":"INFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=run_id%3D%270f4ce9983d6a404081fbdadf04b46adb%27 HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"POST /graphql HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=tags.%60mlflow.prompt.is_prompt%60+%3D+%27true%27+AND+tags.%60mlflow.prompt.run_ids%60+ILIKE+%22%250f4ce9983d6a404081fbdadf04b46adb%25%22 HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"POST /ajax-api/2.0/mlflow/runs/search HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/artifacts/list?run_uuid=0f4ce9983d6a404081fbdadf04b46adb HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /static-files/static/media/fontawesome-webfont.20fd1704ea223900efa9.woff2 HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/artifacts/list?run_uuid=0f4ce9983d6a404081fbdadf04b46adb&path=qa_model HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=run_id%3D%270f4ce9983d6a404081fbdadf04b46adb%27 HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=run_id%3D%270f4ce9983d6a404081fbdadf04b46adb%27 HTTP/1.1\" 200 OK\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/mlflow/server/handlers.py:339: FutureWarning: The filesystem model registry backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n  return FileStore(store_uri)\n","output_type":"stream"},{"name":"stdout","text":"INFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=run_id%3D%270f4ce9983d6a404081fbdadf04b46adb%27 HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"POST /ajax-api/2.0/mlflow/runs/search HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=tags.%60mlflow.prompt.is_prompt%60+%3D+%27true%27+AND+tags.%60mlflow.prompt.run_ids%60+ILIKE+%22%250f4ce9983d6a404081fbdadf04b46adb%25%22 HTTP/1.1\" 200 OK\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/mlflow/server/handlers.py:339: FutureWarning: The filesystem model registry backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n  return FileStore(store_uri)\n","output_type":"stream"},{"name":"stdout","text":"INFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=tags.%60mlflow.prompt.is_prompt%60+%3D+%27true%27+AND+tags.%60mlflow.prompt.run_ids%60+ILIKE+%22%250f4ce9983d6a404081fbdadf04b46adb%25%22 HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"POST /ajax-api/2.0/mlflow/experiments/search-datasets HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/traces?experiment_ids=706558397354895962&order_by=timestamp_ms%20DESC&max_results=1&filter= HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"POST /ajax-api/2.0/mlflow/runs/search HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/gateway-proxy?gateway_path=api%2F2.0%2Fendpoints%2F HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"POST /ajax-api/2.0/mlflow/logged-models/search HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"POST /ajax-api/2.0/mlflow/runs/search HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"POST /ajax-api/3.0/mlflow/ui-telemetry HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"POST /ajax-api/2.0/mlflow/runs/search HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=run_id%3D%270f4ce9983d6a404081fbdadf04b46adb%27 HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=tags.%60mlflow.prompt.is_prompt%60+%3D+%27true%27+AND+tags.%60mlflow.prompt.run_ids%60+ILIKE+%22%250f4ce9983d6a404081fbdadf04b46adb%25%22 HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"POST /ajax-api/2.0/mlflow/runs/search HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/artifacts/list?run_uuid=0f4ce9983d6a404081fbdadf04b46adb HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/artifacts/list?run_uuid=0f4ce9983d6a404081fbdadf04b46adb&path=qa_model HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=run_id%3D%270f4ce9983d6a404081fbdadf04b46adb%27 HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=run_id%3D%270f4ce9983d6a404081fbdadf04b46adb%27 HTTP/1.1\" 200 OK\nINFO:     103.150.255.237:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=run_id%3D%270f4ce9983d6a404081fbdadf04b46adb%27 HTTP/1.1\" 200 OK\nINFO:     103.150.255.237:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=run_id%3D%270f4ce9983d6a404081fbdadf04b46adb%27 HTTP/1.1\" 200 OK\nINFO:     103.150.255.237:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=run_id%3D%270f4ce9983d6a404081fbdadf04b46adb%27 HTTP/1.1\" 200 OK\nINFO:     103.150.255.237:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=run_id%3D%270f4ce9983d6a404081fbdadf04b46adb%27 HTTP/1.1\" 200 OK\nINFO:     103.150.255.237:0 - \"POST /ajax-api/2.0/mlflow/runs/search HTTP/1.1\" 200 OK\nINFO:     103.150.255.237:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=tags.%60mlflow.prompt.is_prompt%60+%3D+%27true%27+AND+tags.%60mlflow.prompt.run_ids%60+ILIKE+%22%250f4ce9983d6a404081fbdadf04b46adb%25%22 HTTP/1.1\" 200 OK\nINFO:     103.150.255.237:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=tags.%60mlflow.prompt.is_prompt%60+%3D+%27true%27+AND+tags.%60mlflow.prompt.run_ids%60+ILIKE+%22%250f4ce9983d6a404081fbdadf04b46adb%25%22 HTTP/1.1\" 200 OK\nINFO:     103.150.255.237:0 - \"GET /static-files/static/js/5839.e1f179e1.chunk.js HTTP/1.1\" 200 OK\nINFO:     103.150.255.237:0 - \"POST /ajax-api/3.0/mlflow/traces/search HTTP/1.1\" 200 OK\nINFO:     103.150.255.237:0 - \"POST /ajax-api/3.0/mlflow/traces/search HTTP/1.1\" 200 OK\n","output_type":"stream"},{"name":"stderr","text":"2026/01/30 17:47:03 ERROR mlflow.server.handlers: Error in _search_evaluation_datasets_handler: search_datasets is not supported with FileStore. This feature requires a SQL-based tracking backend (e.g., SQLite, PostgreSQL, MySQL). Please configure MLflow with a SQL backend using --backend-store-uri. For SQLite setup instructions, see: https://mlflow.org/docs/latest/self-hosting/architecture/tracking-server/#configure-server. Set MLFLOW_LOGGING_LEVEL=DEBUG for traceback.\n","output_type":"stream"},{"name":"stdout","text":"INFO:     103.150.255.237:0 - \"POST /ajax-api/3.0/mlflow/datasets/search HTTP/1.1\" 500 Internal Server Error\nINFO:     103.150.255.237:0 - \"POST /ajax-api/2.0/mlflow/runs/search HTTP/1.1\" 200 OK\nINFO:     103.150.255.237:0 - \"GET /ajax-api/2.0/mlflow/artifacts/list?run_uuid=0f4ce9983d6a404081fbdadf04b46adb HTTP/1.1\" 200 OK\nINFO:     103.150.255.237:0 - \"POST /ajax-api/2.0/mlflow/runs/search HTTP/1.1\" 200 OK\nINFO:     103.150.255.237:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=tags.%60mlflow.prompt.is_prompt%60+%3D+%27true%27+AND+tags.%60mlflow.prompt.run_ids%60+ILIKE+%22%250f4ce9983d6a404081fbdadf04b46adb%25%22 HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=tags.%60mlflow.prompt.is_prompt%60+%3D+%27true%27+AND+tags.%60mlflow.prompt.run_ids%60+ILIKE+%22%250f4ce9983d6a404081fbdadf04b46adb%25%22 HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=tags.%60mlflow.prompt.is_prompt%60+%3D+%27true%27+AND+tags.%60mlflow.prompt.run_ids%60+ILIKE+%22%250f4ce9983d6a404081fbdadf04b46adb%25%22 HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=tags.%60mlflow.prompt.is_prompt%60+%3D+%27true%27+AND+tags.%60mlflow.prompt.run_ids%60+ILIKE+%22%250f4ce9983d6a404081fbdadf04b46adb%25%22 HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=tags.%60mlflow.prompt.is_prompt%60+%3D+%27true%27+AND+tags.%60mlflow.prompt.run_ids%60+ILIKE+%22%250f4ce9983d6a404081fbdadf04b46adb%25%22 HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=tags.%60mlflow.prompt.is_prompt%60+%3D+%27true%27+AND+tags.%60mlflow.prompt.run_ids%60+ILIKE+%22%250f4ce9983d6a404081fbdadf04b46adb%25%22 HTTP/1.1\" 200 OK\nINFO:     103.150.255.235:0 - \"GET /ajax-api/2.0/mlflow/model-versions/search?filter=tags.%60mlflow.prompt.is_prompt%60+%3D+%27true%27+AND+tags.%60mlflow.prompt.run_ids%60+ILIKE+%22%250f4ce9983d6a404081fbdadf04b46adb%25%22 HTTP/1.1\" 200 OK\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}